#!/usr/bin/env python3
"""
Script para iniciar uma nova pipeline de transcodifica√ß√£o
Airflow 3 compatible - Uses API v2 with JWT token authentication
"""
import os

# Set environment variables BEFORE any other imports
os.environ.setdefault('TEMP_DIR', '/tmp/transcode-data')
os.environ.setdefault('DATABASE_URL', 'postgresql://transcode_user:CHANGE_ME_STRONG_PASSWORD_123@localhost:15432/transcode_db')
os.environ.setdefault('REDIS_URL', 'redis://localhost:16379/0')
os.environ.setdefault('MINIO_HOST', 'localhost')
os.environ.setdefault('MINIO_PORT', '19000')
os.environ.setdefault('MINIO_ACCESS_KEY', 'admin')
os.environ.setdefault('MINIO_SECRET_KEY', 'CHANGE_ME_MINIO_PASSWORD_123')
os.environ.setdefault('SECRET_KEY', 'temp-secret-key')

import sys
import requests
from datetime import datetime, timezone
from pathlib import Path

# Configura√ß√£o Airflow 3
AIRFLOW_URL = "http://localhost:18080"
AIRFLOW_USER = "admin"
AIRFLOW_PASSWORD = "CHANGE_ME_AIRFLOW_ADMIN_PASSWORD"
DAG_ID = "video_transcoding_pipeline"


def create_job_in_database(job_id: str, video_path: str):
    """
    Cria o job no banco de dados antes de iniciar a pipeline

    Args:
        job_id: ID do job
        video_path: Path do v√≠deo

    Returns:
        True se sucesso, False caso contr√°rio
    """
    sys.path.insert(0, '/home/transcode-flow')

    try:
        from app.db import SessionLocal
        from app.models.job import Job, JobStatus

        db = SessionLocal()
        try:
            # Verificar se job j√° existe
            existing_job = db.query(Job).filter(Job.job_id == job_id).first()
            if existing_job:
                print(f"‚ö†Ô∏è  Job {job_id} j√° existe no banco de dados")
                return True

            # Criar novo job
            job = Job(
                job_id=job_id,
                source_path=video_path,
                source_filename=Path(video_path).name,
                status=JobStatus.PENDING.value,  # Use .value to get the lowercase string
                created_at=datetime.now(timezone.utc)  # Airflow 3: Use timezone-aware datetime
            )
            db.add(job)
            db.commit()
            print(f"‚úÖ Job criado no banco de dados: {job_id}")
            return True

        except Exception as e:
            print(f"‚ùå Erro ao criar job no banco: {e}")
            db.rollback()
            return False
        finally:
            db.close()

    except Exception as e:
        print(f"‚ùå Erro ao conectar ao banco: {e}")
        return False


def get_airflow_token():
    """
    Get JWT authentication token from Airflow 3

    Returns:
        str: JWT access token
    """
    url = f"{AIRFLOW_URL}/auth/token"
    payload = {
        "username": AIRFLOW_USER,
        "password": AIRFLOW_PASSWORD
    }

    try:
        response = requests.post(url, json=payload)
        if response.status_code in [200, 201]:
            return response.json()["access_token"]
        else:
            raise Exception(f"Failed to get token: {response.status_code} - {response.text}")
    except Exception as e:
        print(f"‚ùå Erro ao obter token de autentica√ß√£o: {e}")
        return None


def trigger_via_airflow(video_path: str, job_id: str = None):
    """
    Trigger pipeline via Airflow 3 API v2 with JWT authentication

    Args:
        video_path: Path to the video file
        job_id: Optional job ID (auto-generated if not provided)
    """
    # Verificar se v√≠deo existe
    if not os.path.exists(video_path):
        print(f"‚ùå ERRO: V√≠deo n√£o encontrado: {video_path}")
        return False

    # Gerar job_id se n√£o fornecido
    if not job_id:
        job_id = f"job-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

    print("=" * 80)
    print("üé¨ INICIANDO PIPELINE DE TRANSCODIFICA√á√ÉO - Airflow 3")
    print("=" * 80)
    print(f"üìπ V√≠deo: {video_path}")
    print(f"üÜî Job ID: {job_id}")
    print()

    # Nota: A DAG criar√° o job no banco de dados automaticamente
    # Remover cria√ß√£o antecipada do job para evitar problemas de permiss√£o

    # Obter token JWT
    print("üîê Obtendo token de autentica√ß√£o...")
    token = get_airflow_token()
    if not token:
        return False
    print("‚úÖ Token obtido com sucesso")
    print()

    # Endpoint da API v2 (Airflow 3)
    url = f"{AIRFLOW_URL}/api/v2/dags/{DAG_ID}/dagRuns"

    # Headers com token JWT
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }

    # Payload - Airflow 3 requires logical_date
    # Use current UTC time for immediate execution
    logical_date = datetime.now(timezone.utc).isoformat()

    payload = {
        "logical_date": logical_date,
        "conf": {
            "job_id": job_id,
            "video_path": video_path
        }
    }

    # Fazer requisi√ß√£o
    print("üì° Enviando requisi√ß√£o para Airflow API v2...")
    try:
        response = requests.post(url, json=payload, headers=headers)

        if response.status_code in [200, 201]:
            try:
                data = response.json()
                dag_run_id = data.get("dag_run_id", data.get("id", "unknown"))

                print("‚úÖ Pipeline iniciada com sucesso!")
                print()
                print("üîó Detalhes:")
                print(f"   DAG Run ID: {dag_run_id}")
                print(f"   Job ID: {job_id}")
                print()
                print(f"üìä Acompanhe em: {AIRFLOW_URL}/dags/{DAG_ID}/grid")
                print()
                return True
            except Exception as e:
                print(f"‚úÖ Pipeline iniciada! (Parsing error: {e})")
                print(f"üìä Acompanhe em: {AIRFLOW_URL}/dags/{DAG_ID}/grid")
                return True
        else:
            print(f"‚ùå Erro ao iniciar pipeline: {response.status_code}")
            print(f"Resposta: {response.text}")

            # Se for 404, dar instru√ß√µes ao usu√°rio
            if response.status_code == 404:
                print()
                print("üí° SOLU√á√ÉO ALTERNATIVA:")
                print(f"   1. Acesse: {AIRFLOW_URL}/dags/{DAG_ID}/grid")
                print("   2. Clique no bot√£o 'Play' (‚ñ∂) para disparar a DAG manualmente")
                print("   3. Use esta configura√ß√£o:")
                print(f'      {{"job_id": "{job_id}", "video_path": "{video_path}"}}')

            return False

    except requests.exceptions.ConnectionError:
        print("‚ùå ERRO: N√£o foi poss√≠vel conectar ao Airflow")
        print(f"   Verifique se o Airflow est√° rodando em {AIRFLOW_URL}")
        return False
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
        return False


def copy_video_to_data_temp(source_video: str, job_id: str = None):
    """
    Copia o v√≠deo para /data/temp para processamento

    Args:
        source_video: Path do v√≠deo original
        job_id: ID do job

    Returns:
        Path do v√≠deo copiado
    """
    if not job_id:
        job_id = f"job-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

    # Criar diret√≥rio de destino
    dest_dir = Path(f"/data/temp/{job_id}")
    dest_dir.mkdir(parents=True, exist_ok=True)

    # Copiar v√≠deo
    source_path = Path(source_video)
    dest_path = dest_dir / source_path.name

    import shutil
    shutil.copy2(source_video, dest_path)

    return str(dest_path)


if __name__ == "__main__":
    # Parse argumentos
    if len(sys.argv) < 2:
        print("Uso: python3 trigger_pipeline.py <caminho_video> [job_id]")
        print()
        print("Exemplo:")
        print("  python3 trigger_pipeline.py /tmp/video.mp4")
        print("  python3 trigger_pipeline.py /tmp/video.mp4 my-custom-job-id")
        sys.exit(1)

    video_path = sys.argv[1]
    job_id = sys.argv[2] if len(sys.argv) > 2 else None

    # Trigger pipeline
    success = trigger_via_airflow(video_path, job_id)

    sys.exit(0 if success else 1)
